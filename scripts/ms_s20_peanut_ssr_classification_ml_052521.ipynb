{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "##This script is to compare different machine learning algrithmns using Python\n",
    "##for the classificaiton of peanut stem rot\n",
    "##By Xing Wei 05/25/2021\n",
    "\n",
    "####################################################################################\n",
    "## 010421 - first draft\n",
    "## 011321 - finalize the algrithms to use for the classification\n",
    "## 013121 - update and add checking the versions of libraries\n",
    "## 030721 - update and add gradient boosting classifer from scikit-learn and XGBoost\n",
    "## 031621 - clean up the codes for the figure preparation\n",
    "## 052521 - clean up the codes for code sharing on Github\n",
    "#################################################################################### \n",
    "\n",
    "##References: \n",
    "##1)https://machinelearningmastery.com/machine-learning-in-python-step-by-step/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.10 (default, Feb 26 2021, 18:47:35) \n",
      "[GCC 7.3.0]\n",
      "scipy: 1.6.1\n",
      "numpy: 1.19.2\n",
      "matplotlib: 3.3.4\n",
      "pandas: 1.2.3\n",
      "sklearn: 0.24.1\n",
      "xgboost: 1.3.3\n"
     ]
    }
   ],
   "source": [
    "# Check the versions of libraries\n",
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "# scipy\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "# numpy\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "# matplotlib\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "# pandas\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "# scikit-learn\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "import xgboost\n",
    "# display version\n",
    "print('xgboost: {}'.format(xgboost.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.naive_bayes import GaussianNB #generative and supervised\n",
    "from sklearn.neighbors import KNeighborsClassifier #discriminative and supervised\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis #discriminative and supervised\n",
    "from sklearn.neural_network import MLPClassifier #discriminative and supervised\n",
    "from sklearn.cross_decomposition import PLSRegression #discriminative and supervised\n",
    "from sklearn.ensemble import RandomForestClassifier #discriminative and supervised\n",
    "from sklearn.svm import SVC #discriminative and supervised\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "dataset = read_csv('../inputs/input_gh2019_all_data.wo.out.binned.cut.csv')\n",
    "# In first column of Type: Healthy; Presymptomatic; Lesion_only; Mild; Severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 157) (399,)\n"
     ]
    }
   ],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "array = dataset.values\n",
    "X = array[:,1:158]\n",
    "y = array[:,0]# define the target variable (dependent variable) as y\n",
    "print (X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = []\n",
    "    models.append(('NB', GaussianNB()))\n",
    "    models.append(('KNN', KNeighborsClassifier()))\n",
    "    models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "    models.append(('MLPNN', MLPClassifier()))\n",
    "    models.append(('RF', RandomForestClassifier()))\n",
    "    models.append(('SVML', SVC(kernel='linear')))\n",
    "    models.append(('SVMR', SVC(kernel='rbf')))\n",
    "    models.append(('GBoost', GradientBoostingClassifier()))\n",
    "    models.append(('XGBoost', XGBClassifier()))\n",
    "    return models\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">NB 0.449 (0.076)\n",
      ">KNN 0.600 (0.060)\n",
      ">LDA 0.591 (0.073)\n",
      ">MLPNN 0.516 (0.078)\n",
      ">RF 0.668 (0.070)\n",
      ">SVML 0.676 (0.074)\n",
      ">SVMR 0.482 (0.048)\n",
      ">GBoost 0.662 (0.068)\n",
      "[20:59:42] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:43] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:44] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:46] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:47] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:49] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:50] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:51] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:53] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:54] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:55] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:57] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:58] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:59:59] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:01] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:02] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:04] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:05] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:06] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:08] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:09] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:10] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:12] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:13] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:15] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:16] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:17] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:19] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:20] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xingwei/.conda/envs/ML2021cas/lib/python3.7/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:00:21] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1614844506100/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      ">XGBoost 0.657 (0.054)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD4CAYAAAD4k815AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAasElEQVR4nO3df5xddX3n8debISyooDPO+GMhEKpRJlCJOqW4xkpWUVALKrQm+FiXbrpsXMHaVR7SThZpecyj7QLqVmjnQRs2j/pYBxQxBDaKuxjFsdLNBCcBjNEAKpFtmZAUG0GZZD77xzmTXG7unXtmcmbOuWfez8fjPmbO93zvOZ+5d+7nfs/3nO/5KiIwM7PqOKroAMzMLF9O7GZmFePEbmZWMU7sZmYV48RuZlYxRxe14+7u7li0aFFRuzcza0tbtmzZHRE9U9UpLLEvWrSIkZGRonZvZtaWJP2kVR13xZiZVYwTu5lZxTixm5lVjBO7mVnFOLGbmVWME7uZWcU4sZuZVYwTu5lZxRQ2QMnMmpOUqZ7nU7BGnNjNSqhRwpbkRG6ZuCvGzKxinNjNzCrGid3MrGKc2M3MKiZTYpd0nqQdknZKuqrB+hdLukvSVkkPS/q9/EM1M7MsWiZ2SR3ATcD5wBJgpaQlddU+Anw/Is4EzgFukHRMzrGamVkGWVrsZwE7I+LRiHgOuBW4sK5OAMcrufj2RcAeYH+ukZqZWSZZEvuJwOM1y7vSslo3Ar3AE8CDwB9ExEQuEZqZ2bRkSeyNhsDVj5J4JzAK/GtgKXCjpBMO25B0maQRSSNjY2PTDNVsdkjK9DBrF1kS+y5gYc3ySSQt81q/B9wRiZ3AY8Bp9RuKiJsjoi8i+np6ppyL1WzORMRhj0blZu0iS2LfDCyWdGp6QnQFsKGuzk+BtwFIejnwWuDRPAM1M7NsWt4rJiL2S7ocuAfoAG6JiIclrU7XDwLXAuskPUjSdfPJiNg9i3GbmVkTmW4CFhEbgY11ZYM1vz8BvCPf0MzMbCY88tTMrGKc2OeBoaEhzjjjDDo6OjjjjDMYGhoqOiQzm0W+H3vFDQ0N0d/fz9q1a1m2bBnDw8OsWrUKgJUrVxYcnZnNBrfYK25gYIC1a9eyfPlyFixYwPLly1m7di0DAwNFh2Zms0RFXZ/b19cXIyMjhex7Puno6OCXv/wlCxYsOFg2Pj7Osccey4EDBwqMrNzKOFtRGWMqgzJOIzibMUnaEhF9U9Vxi73ient7GR4efl7Z8PAwvb29BUVklq8sg8vm+gux6Jic2Cuuv7+fVatWsWnTJsbHx9m0aROrVq2iv7+/6NDMbJb45GnFTZ4gveKKK9i+fTu9vb0MDAz4xKlZhbmP3ayBMvZnlzGmMirj65RnTO5jNzObh5zY5wEPUDKbX9zHXnEeoGQ2/7jFXnEeoGQ2//jkacV5gNLMVP0EXJWV8XXyyVPLlQcomc0/TuwV5wFKZvOPT55WnAcomc0/7mM3a6Dq/bRVVsbXyX3sZmZ2RJzYzcwqxondzKxinNjNzCrGid3MrGJ8uWMOsk6DBXM7PZeZzU9O7DlolKzLeMmVmc0P7ooxM6sYJ3YzaxtdXV1ImvIBtKwjia6uroL/mtnjrhizgnV1dbF3795MdVudz+ns7GTPnj15hFVKe/fuzXMEZy7bKSMndrOCOVlZ3jJ1xUg6T9IOSTslXdVg/ZWSRtPHQ5IOSKrucY6ZWYm1TOySOoCbgPOBJcBKSUtq60TEdRGxNCKWAn8EfCsiqns8aGZWYlla7GcBOyPi0Yh4DrgVuHCK+isBz5ZsZlaQLIn9RODxmuVdadlhJL0AOA/4cpP1l0kakTQyNjY23VhtmrJcGTDf+mSzXFWR9cqKKl9VYe0tS2Jv9Mlvdqbnt4HvNOuGiYibI6IvIvp6enqyxmgzFBHPezQqm2+DqCZPVObxyHoli1VbGS/BzHJVzC5gYc3yScATTequwN0wZjaPlPGqpiwt9s3AYkmnSjqGJHlvaBDQi4G3AnfmEpmZmc1IyxZ7ROyXdDlwD9AB3BIRD0tana4fTKu+D/h6RPxi1qI1M7OWMg1QioiNwMa6ssG65XXAurwCMzOzmfHIU7OCxadOgGtePGWdsY6juLKnm+vHdtN9YGLqbdm858RuVjD9yc9bnnwbvP9aHtjxJQbP/Thrzl7TfFsScU3OAVrb8d0dzUpu7Jkx7tx5J0Gwfud6dj+7u+iQrOSc2M1KbnDbIBORdL9MxASDWwdbPMPmO3fF2JzKep3ubA2carf+7MnW+vjEOADjE+Os37me1Weupvu47lnfv7UnJ3abU/UJe66nEGy3/uza1vqkyVb7VLHZ/OauGLMaZevP3vrk1oOt9UnjE+OMPjlaTEAlN/bMGJd+7dLC37eiucVuVqNRf3aRLePbL7i9sH23o8FtgzzwTw8U/r4VzS12s1Sz/uz53vprF2U72ppUxFGEE7tZaqr+bCu/sl49VHsUMVec2M1S7s9uX2U92irqKMJ97GYp92e3r7JePVTUORu32M2s7ZXxaKvIowgVNYNOX19fjIyMFLLvuTDX12dn4Zjy3V9e2ypjTKXVYnDZ9Lf3dA7baBzTtS/t5CsvehHjRx0alLdgInj/vn2seWqK2bdaxCRpS0T0TVXHXTFm1jayDDDLvK2cBpg1i2nrhosZ37vjeWXjR4nRU/rgisbdfnnF5MQ+A11dXZnmu2w1fL6zs5M9expOD2tmba7IczZO7DOQ1xyHec1vaGZWyydPzcwqxondzKxinNjNzCrGid3MrGJ88tSsBPI6kd7Z2ZnLdqy9ObGbFSzrFVaVH3xkuXFiNzM7QmU74nJin4Es82Zm3o6ZtbUsR1FzfbTlxD4DeQ1rznPOzLxGw0L1R8SWrXVlljcn9orIazQsVHtErPuzbT7w5Y5mZhXjxG5mVjGZEruk8yTtkLRT0lVN6pwjaVTSw5K+lW+Y7aWIyWvNzCa1TOySOoCbgPOBJcBKSUvq6rwE+Cvggog4Hfid/ENtH0VMXmtmNilLi/0sYGdEPBoRzwG3AhfW1bkEuCMifgoQEU/mG2b7KGryWjOzSVkS+4nA4zXLu9KyWq8BOiV9U9IWSR9qtCFJl0kakTQyNjY2o4AlZXoUpdHktWXg7iGriqw5oNWjyperZknsjbJk/XVgRwNvBN4NvBP4r5Jec9iTIm6OiL6I6Ovp6Zl2sOk2Dns0Ki9CkZPXtuLuIauCRp//LPmg0aPKYzWyJPZdwMKa5ZOAJxrU+VpE/CIidgP3AWfmE2L7qG2tTypDq93dQ2bzS5bEvhlYLOlUSccAK4ANdXXuBN4i6WhJLwB+E9ieb6jlt/XJrQdb65PGJ8YZfXK0mIBSZe0eMrPZ0XLkaUTsl3Q5cA/QAdwSEQ9LWp2uH4yI7ZK+BmwDJoC/jYiHZjPwMipy8tpmmnUPrT5zNd3HdRccnZnNhky3FIiIjcDGurLBuuXrgOvyC83yMFX30Jqz1xQUlZnNJo88rbiydg+Z2ezxTcAqrozdQ2Y2u9xiNzOrGLfYKyKvyT8ObsusznQG/vmWx8VyYq+IvCb/gPwmAPHkH9XS6P/L960vJyd2mzWe/MOsGO5jNzOrGCd2M7OKcWI3M6sYJ3Yzs4pxYjczqxgndjOzinFiNzOrGF/HPkN5XFdd5am5zOZKo89io7K5HEhVdExO7DOQ5c3wiDyzuVHGz1nRMbkrxsysYtxir5C8ht27i8isvTmxV4S7h8xskrtizMwqxondzKxinNjNzCrGid3MrGJ88tRmTavp+sY6juLKnm6uH9tN94GJ1tuaJc2uJqovL3qAS6Nynwy3RpzYbda0mq5v8P5reWDHlxg89+OsOXvN1NvKabq+RsqYHMsYk7UPd8VYIcaeGePOnXcSBOt3rmf3s7uLDsmsMpzYrRCD2waZiKT7ZSImGNw6WHBEVq+rqwtJUz6AlnW6uroK/kvmHyd2m3OTrfXxiXEAxifG3WovocnJyI/0sXfv3qL/lHnHid3mXG1rfZJb7Wb5yZTYJZ0naYeknZKuarD+HElPSxpNH1fnH6pVxdYntx5srU8anxhn9MnRYgIyq5iWV8VI6gBuAs4FdgGbJW2IiO/XVf12RLxnFmK0irn9gtuLDqGtDA0NMTAwwPbt2+nt7aW/v5+VK1cWHZaVWJbLHc8CdkbEowCSbgUuBOoTu5nlbGhoiP7+ftauXcuyZcsYHh5m1apVAE7u1lSWrpgTgcdrlnelZfXeJGmrpK9KOj2X6MzmuYGBAdauXcvy5ctZsGABy5cvZ+3atQwMDBQdmpVYlhZ7oyFw9aMnHgBOiYh9kt4FrAcWH7Yh6TLgMoCTTz55epGWWNZRguCBJzY927dvZ9myZc8rW7ZsGdu3by8oImsHWVrsu4CFNcsnAU/UVoiIn0fEvvT3jcACSd31G4qImyOiLyL6enp6jiDscpnOpV9m09Hb28vw8PDzyoaHh+nt7S0oImsHWRL7ZmCxpFMlHQOsADbUVpD0CqXNU0lnpdt9Ku9gzeab/v5+Vq1axaZNmxgfH2fTpk2sWrWK/v7+okOzEmvZFRMR+yVdDtwDdAC3RMTDklan6weBi4EPS9oPPAusCDdPzY7Y5AnSK6644uBVMQMDA6U4cTr2zBhX3ncl17/1erqPO+wA3QqkovJvX19fjIyM5LItT/mWzVy/Tnnuz+9xAaa4MyfAtS/t5EvHv4jf/Zd9rHmqxejSa57OMbD5TdKWiOibqo7v7mhmDU11d86xZ8a4847ziQO/Yn1nN6t/f6Rpq30278xpjfmWAmY2bb6JW7k5sZvZtPgmbuXnxG5m0+KbuJVf6RO77wk9c1lfJ7Pp8E3cyq/0J08n7wl9pOZjAvNVJDYbfBO38it9i93MzKbHid3MrGKc2M3MKsaJ3cysYpzYzcwqpvRXxcSnTpjynhVjHUdxZU8314/tpvvARNN68akTZiM8M7PSKX1in+p+FQCD91/LAzu+xOC5H2fN2Wuab8f3qzCzeaKtu2ImhzYH4SHNJdVq4FjWR2dnZ9F/yrzk9649tXVi942Iyi3rjFJZ6u3Zs6fgv2b+yev983s399o2sftGRGZmjbVtYveNiMzMGmvbxO4bEZmZNVb6q2Ka8Y2IzMwaa9sWu5mZNebEbmZWMU7sZmYV48RuZlYxTuxmZhXjxG5mVjFO7GZmFePEbmZWMU7sZmYV48RuZlYxmRK7pPMk7ZC0U9JVU9T7DUkHJF2cX4hmZjYdLRO7pA7gJuB8YAmwUtKSJvX+Argn7yDNzCy7LC32s4CdEfFoRDwH3Apc2KDeFcCXgSdzjM/MzKYpS2I/EXi8ZnlXWnaQpBOB9wFT3gxd0mWSRiSNjI2NTTdWMzPLIEtiV4Oy+tmlPwt8MiIOTLWhiLg5Ivoioq+npydjiGZmNh1Z7se+C1hYs3wS8ERdnT7gVkkA3cC7JO2PiPV5BGlmZtllSeybgcWSTgV+BqwALqmtEBGnTv4uaR1wt5O6mVkxWib2iNgv6XKSq106gFsi4mFJq9P1nmTUzKxEMk2NFxEbgY11ZQ0TekRceuRhmZnZTHnkqZlZxbTFZNbpSdkj0tnZmUMkZmblV/rEHlF/ZeXhJGWqZ2Y2H7grxsysYkrfYjezcmjWJdqo3EfQxXJiN7NMnKzbh7tizMwqxondzKxinNjNzCrGid3MrGKc2M3MKsaJ3cysYpzYzcwqxtex25xqNJjFA1zM8uXEbnPKCdts9rkrxsysYpzYzcwqxondzKxinNjNzCrGid3MrGKc2M3MKsaJ3cysYpzYzcwqxondzKxinNjNzCrGid3MrGKc2M3MKsaJ3cysYpzYzcwqJlNil3SepB2Sdkq6qsH6CyVtkzQqaUTSsvxDNTOzLFrej11SB3ATcC6wC9gsaUNEfL+m2r3AhogISa8DvgicNhsBm5nZ1LK02M8CdkbEoxHxHHArcGFthYjYF4dmUHgh4NkUzMwKkiWxnwg8XrO8Ky17Hknvk/QD4H8B/6HRhiRdlnbVjIyNjc0kXiQd9mhUbmY2X2VJ7I2y5GEt8oj4SkScBrwXuLbRhiLi5ojoi4i+np6eaQVas41MDzOz+SpLYt8FLKxZPgl4olnliLgPeJWk7iOMzczMZiBLYt8MLJZ0qqRjgBXAhtoKkl6ttP9D0huAY4Cn8g7WzMxaa3lVTETsl3Q5cA/QAdwSEQ9LWp2uHwQuAj4kaRx4FvhAuD/EzKwQKir/9vX1xcjISCH7NjNrV5K2RETfVHU88tTMrGKc2M3MKsaJ3cysYpzYzcwqprCTp5LGgJ/ktLluYHdO28qLY8qmjDFBOeNyTNlUPaZTImLKEZ6FJfY8SRppdZZ4rjmmbMoYE5QzLseUjWNyV4yZWeU4sZuZVUxVEvvNRQfQgGPKpowxQTnjckzZzPuYKtHHbmZmh1SlxW5mZikndjOzimmrxC4pJN1Qs/wJSdekv18j6WfphNo/kPTXknL/+yTtq/n9XZJ+JOnkdP/PSHpZk7pNY887rpqy2tfkR5LukLSkrs7r09jeOcP9hqTP1ywfLWlM0t3p8qWSbmzwvB9LelDSVklfl/SKmvIv19S7WNK6mm1NpPPqTq5/SNKimcSePv9A+vo8JOkuSS9JyxdJejZdN/k4Zqb7abLvfkkP10wE/1VJf1ZXZ6mk7envP5b07br1o5IeSn8/Z/J1L1E8T0v6XvqZvD5jHC+X9AVJj0raIum7SmZom9zeaBrj/6n9vB2p9D2/RNJCSY9J6krLO9PlUyQtlnS3pEfS2DZJ+q203qXp//5o+jreLukFOca3VNK7stRtq8QO/Ap4v5pP4vGZiFgKLAF+HXjrbAUi6W3A54DzIuKnafFu4ONNntIq9tnymYhYGhGLgduAb0iqHdywEhhOf87EL4AzJB2XLp8L/Czjc5dHxJnACPDHNeV9kk5v8pxdQP+MIm3s2fT1OQPYA3ykZt0j6brJx3N57VTSm4D3AG+IiNcBbwf+HPhAXdUVwBdqlo+XtDDdRm8bxPPtiHg98HrgPZLe3CIOAeuB+yLi1yLijek+T6rZ3tI0xs08//06UouASyLiceCvSf5+0p83A/9EMvXnzRHxqjS2K4Bfq9nGbWl8pwPPcfjrdySWApVM7PtJXuA/bFHvGOBYYO9sBCHpLcDfAO+OiEdqVt0CfGDym75O1thnTUTcBnwduAQOfoguBi4F3iHp2Blu+qvAu9PfVwJD03z+fcCra5av5/mJvtbdwOmSXjvNfWTxXRrM5ztLXgnsjohfAUTE7oj4FvDPkn6zpt7vkkwgP+mLHEoWM3mtC4knIp4FRmn9+v5b4Ll0nofJ5/4kIj5XWyn93z2e9DMuqUvS+rQlf//kUd0U5W+tORL7nqTjSRL4WySNAgeAsyV9DFgG3AB8EPhuRBycaCgiHoqIdfV/hKSjgRfWxHeKpHvTOO6VdHKL8t9RchS5VdJ96dHin5Lkl1FJU35htFtiB7gJ+KCkFzdY94fpm/L/gB9GxOgs7P9fAXcC742IH9St20eS3P+gyXOnin2uPACclv7+ZuCx9Mvpm2RsDTRwK7Ai/WJ4HfAP03z+e4AHa5a/CLxB0qsb1J0A/hvNE/+MSOoA3sbzZwd7Vc2H/6Y890fyBbtQ0g8l/ZWkyaPLIZIWKpLOBp6KiB/VPO924P3p778N3NUO8UjqBBaTfIlP5XSS/9FmJhPvT0mOKm5Jy/8E+F7akv9j4O9alH8C+Eh6hP8WkgmCruLQEcENwJXAZ4CPpUdrrWKDNPGSHLV2cej1uBH4uzSO/wn8ZYvyq4F3pke0F6T7v5pDRwS3TRVE2yX2iPg5yZvz0QarJ7tiXga8UNKKWQhhHPh7YFWT9X8J/HtJJ9SvaBH7XKmdnHwlh1pftzLD7piI2EZyGLsS2DiNp25KPwQnALV9uQeA64A/avK8L5C0pk6ddrCHOy6N4SmSD+L/rllX2xWT5yE/EbEPeCNwGTAG3CbpUpL34WIl54dWcHgLeA+wN/3f3g48U/J43iJpG/CPwN0R8Y/TiUvSTWmrdXNaNJl4FwL/g+RLHpJW9efTv+UbwEvTBlSz8u8An5b0UeAlEbG/we7PJ2kkntEktq+kreo7aopvS3PQK0gaK1em5W/iUBfW59O4pir/DrBO0n8kmbluWtousac+S5JYX9hoZUSMA18DfmsW9j1Bcjj6G5IOazVGxD+TvFH/ucnzP8sUsc+B1wPb0xbqRcDVkn5Mcr7g/PSQdCY2kHShTKdrYHn6If1Q+rrV+jzJ+3dy/ZPSD+ENwCdnGGutZ9MP4ikkXXi5JvCpRMSBiPhmRHwKuBy4KO3f/THJ+aGLSI5e6t1GcvSXVzfMbMbz7bQ1+uvAhyUtbRHGw8AbamL6CMmRVKObXm3g0GdcDdZHs/KI+HPg94HjgPslnVZbIY3zXOBskp6AVzaI7X0k3ZiHdb2mU4PeRfMc1GwAUaTPXw2sARYCo5Je2qR+Q22Z2CNiD8k/WMNWc9r/9m+ARxqtz2H/z5B0H3xQUqMYPg38JxrMKdsq9tkk6SLgHSQfwLcDWyNiYUQsiohTgC8D753h5m8B/jQiHmxZM4P0y/kzwMeaVFlH8jdMeZe7aezvaZIjqU9IWpDHNqci6bWSFtcULeXQ3U6HSP72RyJiV4Onf4WkpXpPu8QTET8kOSpr9WX8DeBYSR+uKWt2ZckyDn3G7yPpA0fSOSTnC37erFzSqyLiwYj4C5KT96cB/0JyMlgkJ08/ll4YcR1Jo+ULwJslXZAhtvr4/p60SyuNZ3iq8jS+f4iIq0kuylg4Gd8U+zskItrmAeyr+f3lJId916TL15D0a42SfLMOAcfNcgwLgceAC9P9f6Jm3adJv7hbxZ5TXBMkV4xMPv5L3WvyI5IP4JK0/jpgdd02LgC+OtPXo6bsHJLDbkhaNPvqYjuJpBXY3eC5B8tJzmc8Aayr2daNNXU/StLCWZTH+5ku3wX8O5KupYdm8X/5jSQf6u8D24A7av7uHpIuv/r357DXrDbO9HV/tu61flPB8dxds+649P/x1BaxvJKkC+gx4P8Cm0hO0J4DPJ3+P28lSdqvSZ/TRXLuaxtwP/C6FuWfAx5KtzOU/q8tAO4FHifpl5+MpwPYQnLUchpJd+OjJCfbvw68veb/cyyNb1ta72U1r8s30vJ7gZNblN9B0pXzEPDfSY48ukiuBBoFPjDVa+hbCpiZVUxbdsWYmVlzTuxmZhXjxG5mVjFO7GZmFePEbmZWMU7sZmYV48RuZlYx/x8jviW5T/HkDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare the classification accuracy using ALL wavelengths\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    accuracy = evaluate_model(model, X, y)\n",
    "    results.append(accuracy)\n",
    "    names.append(name)\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(accuracy), std(accuracy)))\n",
    "# plot model performance for comparison\n",
    "plt.boxplot(results, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB</th>\n",
       "      <th>KNN</th>\n",
       "      <th>LDA</th>\n",
       "      <th>MLPNN</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVML</th>\n",
       "      <th>SVMR</th>\n",
       "      <th>GBoost</th>\n",
       "      <th>XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.692308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.475000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.589744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NB       KNN       LDA     MLPNN        RF      SVML      SVMR  \\\n",
       "0   0.550000  0.650000  0.775000  0.600000  0.650000  0.700000  0.475000   \n",
       "1   0.375000  0.625000  0.625000  0.450000  0.750000  0.675000  0.475000   \n",
       "2   0.400000  0.550000  0.575000  0.525000  0.600000  0.625000  0.450000   \n",
       "3   0.500000  0.625000  0.600000  0.575000  0.675000  0.825000  0.500000   \n",
       "4   0.475000  0.500000  0.525000  0.600000  0.700000  0.575000  0.425000   \n",
       "5   0.375000  0.525000  0.475000  0.350000  0.525000  0.500000  0.450000   \n",
       "6   0.375000  0.650000  0.550000  0.550000  0.750000  0.575000  0.500000   \n",
       "7   0.475000  0.675000  0.700000  0.425000  0.725000  0.700000  0.525000   \n",
       "8   0.475000  0.600000  0.625000  0.500000  0.700000  0.725000  0.500000   \n",
       "9   0.461538  0.615385  0.487179  0.564103  0.692308  0.717949  0.538462   \n",
       "10  0.450000  0.575000  0.525000  0.675000  0.600000  0.675000  0.525000   \n",
       "11  0.375000  0.525000  0.550000  0.425000  0.550000  0.525000  0.425000   \n",
       "12  0.425000  0.525000  0.575000  0.525000  0.625000  0.725000  0.450000   \n",
       "13  0.475000  0.625000  0.700000  0.625000  0.775000  0.675000  0.500000   \n",
       "14  0.600000  0.625000  0.600000  0.575000  0.700000  0.700000  0.550000   \n",
       "15  0.425000  0.625000  0.575000  0.450000  0.625000  0.725000  0.525000   \n",
       "16  0.325000  0.550000  0.525000  0.525000  0.550000  0.575000  0.400000   \n",
       "17  0.400000  0.550000  0.500000  0.475000  0.675000  0.800000  0.475000   \n",
       "18  0.575000  0.600000  0.600000  0.675000  0.800000  0.800000  0.525000   \n",
       "19  0.461538  0.692308  0.538462  0.410256  0.769231  0.641026  0.435897   \n",
       "20  0.600000  0.675000  0.750000  0.525000  0.775000  0.700000  0.550000   \n",
       "21  0.575000  0.650000  0.700000  0.425000  0.650000  0.675000  0.575000   \n",
       "22  0.475000  0.500000  0.575000  0.450000  0.675000  0.625000  0.475000   \n",
       "23  0.400000  0.625000  0.525000  0.425000  0.625000  0.700000  0.500000   \n",
       "24  0.500000  0.650000  0.600000  0.575000  0.675000  0.750000  0.500000   \n",
       "25  0.300000  0.500000  0.600000  0.525000  0.700000  0.625000  0.375000   \n",
       "26  0.375000  0.625000  0.600000  0.550000  0.600000  0.700000  0.475000   \n",
       "27  0.450000  0.725000  0.575000  0.525000  0.675000  0.675000  0.475000   \n",
       "28  0.375000  0.600000  0.550000  0.475000  0.600000  0.675000  0.500000   \n",
       "29  0.461538  0.538462  0.641026  0.512821  0.615385  0.692308  0.384615   \n",
       "\n",
       "      GBoost   XGBoost  \n",
       "0   0.700000  0.725000  \n",
       "1   0.600000  0.700000  \n",
       "2   0.700000  0.650000  \n",
       "3   0.650000  0.600000  \n",
       "4   0.700000  0.650000  \n",
       "5   0.550000  0.550000  \n",
       "6   0.700000  0.625000  \n",
       "7   0.550000  0.625000  \n",
       "8   0.725000  0.725000  \n",
       "9   0.717949  0.692308  \n",
       "10  0.650000  0.575000  \n",
       "11  0.575000  0.650000  \n",
       "12  0.650000  0.650000  \n",
       "13  0.600000  0.675000  \n",
       "14  0.725000  0.725000  \n",
       "15  0.650000  0.625000  \n",
       "16  0.575000  0.600000  \n",
       "17  0.600000  0.600000  \n",
       "18  0.775000  0.750000  \n",
       "19  0.717949  0.717949  \n",
       "20  0.750000  0.725000  \n",
       "21  0.675000  0.650000  \n",
       "22  0.550000  0.625000  \n",
       "23  0.650000  0.625000  \n",
       "24  0.750000  0.775000  \n",
       "25  0.775000  0.675000  \n",
       "26  0.725000  0.625000  \n",
       "27  0.625000  0.675000  \n",
       "28  0.650000  0.625000  \n",
       "29  0.589744  0.589744  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build a dataframe including cross validation accuracy for each machine learning methods\n",
    "df_clf_accuracy = pd.DataFrame(results)\n",
    "# transpose the dataframe\n",
    "df_clf_accuracy = df_clf_accuracy.T\n",
    "#naming the dataframe columns\n",
    "df_clf_accuracy.columns = names\n",
    "df_clf_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe of cross validation accuracy to CVS file\n",
    "df_clf_accuracy.to_csv(r'../results/R20_peanut_all_clf_accuracy.csv', encoding='utf-8', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
